{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb2cf45",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) with Scikit-learn Wrapper (SVM_SK)\n",
    "\n",
    "## 1. Import Required Libraries\n",
    "In this section, we import the necessary libraries for loading data, applying the custom `SVM_SK` class, and visualizing the results. We also import the `SVM_SK` class from `src/sklearn_impl/SVM_SK.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification  # For generating synthetic classification data\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add path to access src/sklearn_impl/SVM_SK.py\n",
    "sys.path.append(os.path.abspath('../src/sklearn_impl'))\n",
    "from SVM_SK import SVM_SK  # Import from src/sklearn_impl/SVM_SK.py\n",
    "\n",
    "# Plotting settings\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee81c37",
   "metadata": {},
   "source": [
    "## 2. Generate or Load Data\n",
    "We will generate synthetic classification data using `make_classification` for demonstration purposes. If you have your own data (e.g., `placeholder_1.csv` in the repo), you can replace this section with loading your CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38529873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/placeholder_1.csv')  # Adjust path \n",
    "X = df[['Feature_1', 'Feature_2']].values\n",
    "y = df['Label'].values  # Ensure labels are {-1, 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3f87e1",
   "metadata": {},
   "source": [
    "## 3. Apply SVM_SK (Scikit-learn Wrapper)\n",
    "We will use the `SVM_SK` class with the 'sgd' method (iterative training with early stopping) to train the model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM_SK model with SGD method and early stopping\n",
    "svm_sk = SVM_SK(\n",
    "    method='sgd',\n",
    "    C=1.0,\n",
    "    tol=1e-3,\n",
    "    max_iter=1000,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    verbose=True,\n",
    "    interval=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "svm_sk.fit(X, y)\n",
    "\n",
    "# Predict labels for the training data\n",
    "df['Predicted_Label'] = svm_sk.predict(X)\n",
    "\n",
    "# Display the first 5 rows with predicted labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72608679",
   "metadata": {},
   "source": [
    "## 4. Visualize the Results\n",
    "We will plot the data points colored by their true and predicted labels. Since the 'sgd' method does not directly provide support vectors or a decision boundary (unlike SVC with a linear kernel), we'll visualize the classification results only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a46a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data points\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='Feature_1', y='Feature_2', hue='Label', style='Predicted_Label', \n",
    "                data=df, palette='Set1', s=100)\n",
    "\n",
    "plt.title('SVM_SK Classification Results (SGD Method)')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dcfb42",
   "metadata": {},
   "source": [
    "## 5. Plot Loss History\n",
    "We will plot the hinge loss history tracked by `SVM_SK` to observe the convergence of the model, especially with early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c53be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loss history\n",
    "loss_history = svm_sk.get_loss_history()\n",
    "\n",
    "# Plot loss history\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(loss_history, marker='o')\n",
    "plt.title('Hinge Loss History Over Epochs (SVM_SK with SGD)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Hinge Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df800f",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model\n",
    "We will compute the accuracy score of the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy\n",
    "accuracy = svm_sk.score(X, y)\n",
    "print(f\"Accuracy on training data: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a62ff",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "In this notebook, we implemented the `SVM_SK` class, a scikit-learn wrapper using either `SVC` or `SGDClassifier` with hinge loss. We used the 'sgd' method with early stopping, generated synthetic classification data, trained the model, visualized the results, plotted the loss history, and evaluated the accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
