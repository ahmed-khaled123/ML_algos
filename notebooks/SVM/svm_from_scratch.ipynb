{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ad973f",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) from Scratch\n",
    "\n",
    "## 1. Import Required Libraries\n",
    "In this section, we import the necessary libraries for loading data, applying the custom `SVM` class, and visualizing the results. We also import the `SVM` class from the appropriate module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297cc3e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification  # For generating synthetic classification data\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add path to access src/models/SVM.py and related utilities\n",
    "sys.path.append(os.path.abspath('../src/models'))\n",
    "sys.path.append(os.path.abspath('../src/utils'))  # For math_utils.py and smo_utils.py\n",
    "from SVM import SVM  # Import from src/models/SVM.py\n",
    "\n",
    "# Plotting settings\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f568e9e7",
   "metadata": {},
   "source": [
    "## 2. Generate or Load Data\n",
    "We will generate synthetic classification data using `make_classification` for demonstration purposes. If you have your own data (e.g., `placeholder_1.csv` in the repo), you can replace this section with loading your CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260c45d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/placeholder_1.csv')  # Adjust path if needed\n",
    "X = df[['Feature_1', 'Feature_2']].values\n",
    "y = df['Label'].values  # Ensure labels are {-1, 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18423751",
   "metadata": {},
   "source": [
    "## 3. Apply SVM (From Scratch)\n",
    "We will use the custom `SVM` class, which implements the SMO algorithm, to train the model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3590ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create SVM model with a linear kernel\n",
    "svm = SVM(C=1.0, tol=1e-3, max_passes=5, kernel='linear', verbose=True)\n",
    "\n",
    "# Train the model\n",
    "svm.fit(X, y)\n",
    "\n",
    "# Predict labels for the training data\n",
    "df['Predicted_Label'] = svm.predict(X)\n",
    "\n",
    "# Display the first 5 rows with predicted labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c995943b",
   "metadata": {},
   "source": [
    "## 4. Visualize the Results\n",
    "We will plot the data points colored by their true and predicted labels, and highlight the support vectors. We will also plot the decision boundary (for linear kernel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a6b71",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the data points and decision boundary\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot data points\n",
    "sns.scatterplot(x='Feature_1', y='Feature_2', hue='Label', style='Predicted_Label', \n",
    "                data=df, palette='Set1', s=100)\n",
    "\n",
    "# Highlight support vectors\n",
    "plt.scatter(svm.support_vectors_[:, 0], svm.support_vectors_[:, 1], \n",
    "            s=200, facecolors='none', edgecolors='black', label='Support Vectors')\n",
    "\n",
    "# Plot decision boundary (for linear kernel)\n",
    "if svm.kernel == 'linear':\n",
    "    # Get the separating hyperplane\n",
    "    w = np.sum((svm.support_alphas_ * svm.support_y_)[:, np.newaxis] * svm.support_vectors_, axis=0)\n",
    "    b = svm.b\n",
    "    x1 = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)\n",
    "    x2 = -(w[0] * x1 + b) / w[1]\n",
    "    plt.plot(x1, x2, 'k-', label='Decision Boundary')\n",
    "\n",
    "    # Plot margins\n",
    "    x2_margin1 = -(w[0] * x1 + b + 1) / w[1]\n",
    "    x2_margin2 = -(w[0] * x1 + b - 1) / w[1]\n",
    "    plt.plot(x1, x2_margin1, 'k--', label='Margins')\n",
    "    plt.plot(x1, x2_margin2, 'k--')\n",
    "\n",
    "plt.title('SVM Classification Results (From Scratch)')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787c65a",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "In this notebook, we implemented a Support Vector Machine (SVM) from scratch using the SVM algorithm from `src/models/SVM.py`. We generated synthetic classification data, trained the model with a linear kernel, visualized the results including the decision boundary and support vectors, and evaluated the predictions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
