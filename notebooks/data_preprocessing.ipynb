{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Data Preprocessing for Student Performance and Breast Cancer Datasets\n",
    "\n",
    " This notebook preprocesses two datasets:\n",
    "\n",
    " - **Student_Performance.csv**: A regression dataset predicting `Performance Index`.\n",
    "\n",
    " - **breast-cancer.csv**: A classification dataset predicting `diagnosis` (Malignant/Benign).\n",
    "\n",
    "\n",
    "\n",
    " The steps include loading data, handling missing values, encoding categorical variables, normalizing features, splitting into training/test sets, and saving the processed data as NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Setup\n",
    "\n",
    " Import necessary libraries and set up the project root for file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set project root directory\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.scratch.utils.data_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Student Performance Preprocessing (Regression)\n",
    "\n",
    " Prepares the `Student_Performance.csv` dataset for a regression task to predict `Performance Index`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Load and Inspect Data\n",
    "\n",
    " Load the dataset and display basic information to confirm structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Performance Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Hours Studied                     10000 non-null  int64  \n",
      " 1   Previous Scores                   10000 non-null  int64  \n",
      " 2   Extracurricular Activities        10000 non-null  object \n",
      " 3   Sleep Hours                       10000 non-null  int64  \n",
      " 4   Sample Question Papers Practiced  10000 non-null  int64  \n",
      " 5   Performance Index                 10000 non-null  float64\n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 468.9+ KB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "   Hours Studied  Previous Scores Extracurricular Activities  Sleep Hours  \\\n",
      "0              7               99                        Yes            9   \n",
      "1              4               82                         No            4   \n",
      "2              8               51                        Yes            7   \n",
      "3              5               52                        Yes            5   \n",
      "4              7               75                         No            8   \n",
      "\n",
      "   Sample Question Papers Practiced  Performance Index  \n",
      "0                                 1               91.0  \n",
      "1                                 2               65.0  \n",
      "2                                 2               45.0  \n",
      "3                                 2               36.0  \n",
      "4                                 5               66.0  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data_path = \"../data/raw/Regression_Dataset/Student_Performance.csv\"\n",
    "df = load_data(data_path)  # Assumes load_data() is a utility function that reads CSV\n",
    "\n",
    "# Display basic info and first few rows\n",
    "print(\"Student Performance Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Encode Categorical Columns\n",
    "\n",
    " - `Extracurricular Activities` is the only categorical column (object type, 'Yes'/'No').\n",
    "\n",
    " - Encode it to numerical values (e.g., Yes=1, No=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode_categorical(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Handle Missing Values\n",
    "\n",
    " - From `df.info()`, there are no missing values (10,000 non-null entries per column).\n",
    "\n",
    " - Apply the function for completeness and robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = handle_missing_values(df, strategy=\"mean\")  # Uses mean imputation if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Split Features and Target\n",
    "\n",
    " - **Target**: `Performance Index` (float64, continuous for regression).\n",
    "\n",
    " - **Features**: All other columns (`Hours Studied`, `Previous Scores`, `Extracurricular Activities`, `Sleep Hours`, `Sample Question Papers Practiced`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"Performance Index\"\n",
    "X, y = feature_target_split(df, target_column)  # Splits features (X) and target (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Normalize Features\n",
    "\n",
    " - Normalize only the feature columns (X) to ensure consistent scale.\n",
    "\n",
    " - Do not normalize the target (`Performance Index`) as itâ€™s a regression output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Convert to NumPy Arrays\n",
    "\n",
    " - Convert features and target to NumPy arrays for compatibility with machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Split into Training and Test Sets\n",
    "\n",
    " - Split data into 80% training and 20% testing for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Save Processed Data\n",
    "\n",
    " - Save the processed arrays to the `../data/processed/` directory for use in training scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Student Performance data processed and saved.\n"
     ]
    }
   ],
   "source": [
    "np.save(\"../data/processed/student_X_train.npy\", X_train)\n",
    "np.save(\"../data/processed/student_X_test.npy\", X_test)\n",
    "np.save(\"../data/processed/student_y_train.npy\", y_train)\n",
    "np.save(\"../data/processed/student_y_test.npy\", y_test)\n",
    "\n",
    "print(\"\\nStudent Performance data processed and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Breast Cancer Preprocessing (Classification)\n",
    "\n",
    " Prepares the `breast-cancer.csv` dataset for a classification task to predict `diagnosis`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Load and Inspect Data\n",
    "\n",
    " Load the dataset and display basic information to confirm structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
      "0  ...         25.38          17.33           184.60      2019.0   \n",
      "1  ...         24.99          23.41           158.80      1956.0   \n",
      "2  ...         23.57          25.53           152.50      1709.0   \n",
      "3  ...         14.91          26.50            98.87       567.7   \n",
      "4  ...         22.54          16.67           152.20      1575.0   \n",
      "\n",
      "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   symmetry_worst  fractal_dimension_worst  \n",
      "0          0.4601                  0.11890  \n",
      "1          0.2750                  0.08902  \n",
      "2          0.3613                  0.08758  \n",
      "3          0.6638                  0.17300  \n",
      "4          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data_path = \"../data/raw/Classification_Dataset/breast-cancer.csv\"\n",
    "df = load_data(data_path)\n",
    "\n",
    "# Display basic info and first few rows\n",
    "print(\"Breast Cancer Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Drop Irrelevant Columns\n",
    "\n",
    " - `id` column is irrelevant for modeling and should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_columns(df, [\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Encode Target Column\n",
    "\n",
    " - `diagnosis` is the target column (object type, 'M' for malignant, 'B' for benign).\n",
    "\n",
    " - Map 'M' to 1 and 'B' to 0 for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diagnosis\"] = df[\"diagnosis\"].map({\"M\": 1, \"B\": 0}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Handle Missing Values\n",
    "\n",
    " - From `df.info()`, there are no missing values (569 non-null entries per column).\n",
    "\n",
    " - Apply the function for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = handle_missing_values(df, strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Split Features and Target\n",
    "\n",
    " - **Target**: `diagnosis` (now int, binary for classification).\n",
    "\n",
    " - **Features**: All other columns (30 numerical features like `radius_mean`, `texture_mean`, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"diagnosis\"\n",
    "X, y = feature_target_split(df, target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Encode Categorical Columns in Features\n",
    "\n",
    " - No categorical columns in features (all are float64 after dropping `id` and encoding `diagnosis`).\n",
    "\n",
    " - Apply the function as a safeguard for future datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encode_categorical(X)  # No-op in this case, but ensures robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Normalize Features\n",
    "\n",
    " - Normalize only the feature columns (X) to ensure consistent scale.\n",
    "\n",
    " - Do not normalize the target (`diagnosis`) as itâ€™s a binary label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Convert to NumPy Arrays\n",
    "\n",
    " - Convert features and target to NumPy arrays for model compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Split into Training and Test Sets\n",
    "\n",
    " - Split data into 80% training and 20% testing for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Save Processed Data\n",
    "\n",
    " - Save the processed arrays to the `../data/processed/` directory for use in training scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Breast Cancer data processed and saved.\n"
     ]
    }
   ],
   "source": [
    "np.save(\"../data/processed/breast_cancer_X_train.npy\", X_train)\n",
    "np.save(\"../data/processed/breast_cancer_X_test.npy\", X_test)\n",
    "np.save(\"../data/processed/breast_cancer_y_train.npy\", y_train)\n",
    "np.save(\"../data/processed/breast_cancer_y_test.npy\", y_test)\n",
    "\n",
    "print(\"\\nBreast Cancer data processed and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
